// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/assistant/embedded/v1alpha1/embedded_assistant.proto

package com.google.assistant.embedded.v1alpha1;

/**
 * <pre>
 * The semantic result for the user's spoken query.
 * </pre>
 *
 * Protobuf type {@code google.assistant.embedded.v1alpha1.ConverseResult} */
public final class ConverseResult extends com.google.protobuf.GeneratedMessageV3 implements
// @@protoc_insertion_point(message_implements:google.assistant.embedded.v1alpha1.ConverseResult)
	ConverseResultOrBuilder {
	// Use ConverseResult.newBuilder() to construct.
	private ConverseResult (com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
		super(builder);
	}

	private ConverseResult () {
		spokenRequestText_ = "";
		spokenResponseText_ = "";
		conversationState_ = com.google.protobuf.ByteString.EMPTY;
		microphoneMode_ = 0;
		volumePercentage_ = 0;
	}

	@java.lang.Override
	public final com.google.protobuf.UnknownFieldSet getUnknownFields () {
		return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
	}

	private ConverseResult (com.google.protobuf.CodedInputStream input,
		com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException {
		this();
		int mutable_bitField0_ = 0;
		try {
			boolean done = false;
			while (!done) {
				int tag = input.readTag();
				switch (tag) {
				case 0:
					done = true;
					break;
				default: {
					if (!input.skipField(tag)) {
						done = true;
					}
					break;
				}
				case 10: {
					java.lang.String s = input.readStringRequireUtf8();

					spokenRequestText_ = s;
					break;
				}
				case 18: {
					java.lang.String s = input.readStringRequireUtf8();

					spokenResponseText_ = s;
					break;
				}
				case 26: {

					conversationState_ = input.readBytes();
					break;
				}
				case 32: {
					int rawValue = input.readEnum();

					microphoneMode_ = rawValue;
					break;
				}
				case 40: {

					volumePercentage_ = input.readInt32();
					break;
				}
				}
			}
		} catch (com.google.protobuf.InvalidProtocolBufferException e) {
			throw e.setUnfinishedMessage(this);
		} catch (java.io.IOException e) {
			throw new com.google.protobuf.InvalidProtocolBufferException(e).setUnfinishedMessage(this);
		} finally {
			makeExtensionsImmutable();
		}
	}

	public static final com.google.protobuf.Descriptors.Descriptor getDescriptor () {
		return com.google.assistant.embedded.v1alpha1.AssistantProto.internal_static_google_assistant_embedded_v1alpha1_ConverseResult_descriptor;
	}

	protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable () {
		return com.google.assistant.embedded.v1alpha1.AssistantProto.internal_static_google_assistant_embedded_v1alpha1_ConverseResult_fieldAccessorTable
			.ensureFieldAccessorsInitialized(com.google.assistant.embedded.v1alpha1.ConverseResult.class,
				com.google.assistant.embedded.v1alpha1.ConverseResult.Builder.class);
	}

	/**
	 * <pre>
	 * Possible states of the microphone after a `Converse` RPC completes.
	 * </pre>
	 *
	 * Protobuf enum {@code google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode} */
	public enum MicrophoneMode implements com.google.protobuf.ProtocolMessageEnum {
		/**
		 * <pre>
		 * No mode specified.
		 * </pre>
		 *
		 * <code>MICROPHONE_MODE_UNSPECIFIED = 0;</code> */
		MICROPHONE_MODE_UNSPECIFIED(0),
		/**
		 * <pre>
		 * The service is not expecting a follow-on question from the user.
		 * The microphone should remain off until the user re-activates it.
		 * </pre>
		 *
		 * <code>CLOSE_MICROPHONE = 1;</code> */
		CLOSE_MICROPHONE(1),
		/**
		 * <pre>
		 * The service is expecting a follow-on question from the user. The
		 * microphone should be re-opened when the `AudioOut` playback completes
		 * (by starting a new `Converse` RPC call to send the new audio).
		 * </pre>
		 *
		 * <code>DIALOG_FOLLOW_ON = 2;</code> */
		DIALOG_FOLLOW_ON(2), UNRECOGNIZED(-1),;

		/**
		 * <pre>
		 * No mode specified.
		 * </pre>
		 *
		 * <code>MICROPHONE_MODE_UNSPECIFIED = 0;</code> */
		public static final int MICROPHONE_MODE_UNSPECIFIED_VALUE = 0;
		/**
		 * <pre>
		 * The service is not expecting a follow-on question from the user.
		 * The microphone should remain off until the user re-activates it.
		 * </pre>
		 *
		 * <code>CLOSE_MICROPHONE = 1;</code> */
		public static final int CLOSE_MICROPHONE_VALUE = 1;
		/**
		 * <pre>
		 * The service is expecting a follow-on question from the user. The
		 * microphone should be re-opened when the `AudioOut` playback completes
		 * (by starting a new `Converse` RPC call to send the new audio).
		 * </pre>
		 *
		 * <code>DIALOG_FOLLOW_ON = 2;</code> */
		public static final int DIALOG_FOLLOW_ON_VALUE = 2;

		public final int getNumber () {
			if (this == UNRECOGNIZED) {
				throw new java.lang.IllegalArgumentException("Can't get the number of an unknown enum value.");
			}
			return value;
		}

		/** @deprecated Use {@link #forNumber(int)} instead. */
		@java.lang.Deprecated
		public static MicrophoneMode valueOf (int value) {
			return forNumber(value);
		}

		public static MicrophoneMode forNumber (int value) {
			switch (value) {
			case 0:
				return MICROPHONE_MODE_UNSPECIFIED;
			case 1:
				return CLOSE_MICROPHONE;
			case 2:
				return DIALOG_FOLLOW_ON;
			default:
				return null;
			}
		}

		public static com.google.protobuf.Internal.EnumLiteMap<MicrophoneMode> internalGetValueMap () {
			return internalValueMap;
		}

		private static final com.google.protobuf.Internal.EnumLiteMap<MicrophoneMode> internalValueMap = new com.google.protobuf.Internal.EnumLiteMap<MicrophoneMode>() {
			public MicrophoneMode findValueByNumber (int number) {
				return MicrophoneMode.forNumber(number);
			}
		};

		public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor () {
			return getDescriptor().getValues().get(ordinal());
		}

		public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType () {
			return getDescriptor();
		}

		public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor () {
			return com.google.assistant.embedded.v1alpha1.ConverseResult.getDescriptor().getEnumTypes().get(0);
		}

		private static final MicrophoneMode[] VALUES = values();

		public static MicrophoneMode valueOf (com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
			if (desc.getType() != getDescriptor()) {
				throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");
			}
			if (desc.getIndex() == -1) {
				return UNRECOGNIZED;
			}
			return VALUES[desc.getIndex()];
		}

		private final int value;

		private MicrophoneMode (int value) {
			this.value = value;
		}

		// @@protoc_insertion_point(enum_scope:google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode)
	}

	public static final int SPOKEN_REQUEST_TEXT_FIELD_NUMBER = 1;
	private volatile java.lang.Object spokenRequestText_;

	/**
	 * <pre>
	 * *Output-only* The recognized transcript of what the user said.
	 * </pre>
	 *
	 * <code>string spoken_request_text = 1;</code> */
	public java.lang.String getSpokenRequestText () {
		java.lang.Object ref = spokenRequestText_;
		if (ref instanceof java.lang.String) {
			return (java.lang.String)ref;
		} else {
			com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString)ref;
			java.lang.String s = bs.toStringUtf8();
			spokenRequestText_ = s;
			return s;
		}
	}

	/**
	 * <pre>
	 * *Output-only* The recognized transcript of what the user said.
	 * </pre>
	 *
	 * <code>string spoken_request_text = 1;</code> */
	public com.google.protobuf.ByteString getSpokenRequestTextBytes () {
		java.lang.Object ref = spokenRequestText_;
		if (ref instanceof java.lang.String) {
			com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String)ref);
			spokenRequestText_ = b;
			return b;
		} else {
			return (com.google.protobuf.ByteString)ref;
		}
	}

	public static final int SPOKEN_RESPONSE_TEXT_FIELD_NUMBER = 2;
	private volatile java.lang.Object spokenResponseText_;

	/**
	 * <pre>
	 * *Output-only* The text of the assistant's spoken response. This is only
	 * returned for an IFTTT action.
	 * </pre>
	 *
	 * <code>string spoken_response_text = 2;</code> */
	public java.lang.String getSpokenResponseText () {
		java.lang.Object ref = spokenResponseText_;
		if (ref instanceof java.lang.String) {
			return (java.lang.String)ref;
		} else {
			com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString)ref;
			java.lang.String s = bs.toStringUtf8();
			spokenResponseText_ = s;
			return s;
		}
	}

	/**
	 * <pre>
	 * *Output-only* The text of the assistant's spoken response. This is only
	 * returned for an IFTTT action.
	 * </pre>
	 *
	 * <code>string spoken_response_text = 2;</code> */
	public com.google.protobuf.ByteString getSpokenResponseTextBytes () {
		java.lang.Object ref = spokenResponseText_;
		if (ref instanceof java.lang.String) {
			com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String)ref);
			spokenResponseText_ = b;
			return b;
		} else {
			return (com.google.protobuf.ByteString)ref;
		}
	}

	public static final int CONVERSATION_STATE_FIELD_NUMBER = 3;
	private com.google.protobuf.ByteString conversationState_;

	/**
	 * <pre>
	 * *Output-only* State information for subsequent `ConverseRequest`. This
	 * value should be saved in the client and returned in the
	 * `conversation_state` with the next `ConverseRequest`. (The client does not
	 * need to interpret or otherwise use this value.) There is no need to save
	 * this information across device restarts.
	 * </pre>
	 *
	 * <code>bytes conversation_state = 3;</code> */
	public com.google.protobuf.ByteString getConversationState () {
		return conversationState_;
	}

	public static final int MICROPHONE_MODE_FIELD_NUMBER = 4;
	private int microphoneMode_;

	/**
	 * <pre>
	 * *Output-only* Specifies the mode of the microphone after this `Converse`
	 * RPC is processed.
	 * </pre>
	 *
	 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
	public int getMicrophoneModeValue () {
		return microphoneMode_;
	}

	/**
	 * <pre>
	 * *Output-only* Specifies the mode of the microphone after this `Converse`
	 * RPC is processed.
	 * </pre>
	 *
	 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
	public com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode getMicrophoneMode () {
		com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode result = com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode
			.valueOf(microphoneMode_);
		return result == null ? com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode.UNRECOGNIZED : result;
	}

	public static final int VOLUME_PERCENTAGE_FIELD_NUMBER = 5;
	private int volumePercentage_;

	/**
	 * <pre>
	 * *Output-only* Updated volume level. The value will be 0 or omitted
	 * (indicating no change) unless a voice command such as "Increase the volume"
	 * or "Set volume level 4" was recognized, in which case the value will be
	 * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
	 * Typically, a client should use this volume level when playing the
	 * `audio_out` data, and retain this value as the current volume level and
	 * supply it in the `AudioOutConfig` of the next `ConverseRequest`. (Some
	 * clients may also implement other ways to allow the current volume level to
	 * be changed, for example, by providing a knob that the user can turn.)
	 * </pre>
	 *
	 * <code>int32 volume_percentage = 5;</code> */
	public int getVolumePercentage () {
		return volumePercentage_;
	}

	private byte memoizedIsInitialized = -1;

	public final boolean isInitialized () {
		byte isInitialized = memoizedIsInitialized;
		if (isInitialized == 1) return true;
		if (isInitialized == 0) return false;

		memoizedIsInitialized = 1;
		return true;
	}

	public void writeTo (com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
		if (!getSpokenRequestTextBytes().isEmpty()) {
			com.google.protobuf.GeneratedMessageV3.writeString(output, 1, spokenRequestText_);
		}
		if (!getSpokenResponseTextBytes().isEmpty()) {
			com.google.protobuf.GeneratedMessageV3.writeString(output, 2, spokenResponseText_);
		}
		if (!conversationState_.isEmpty()) {
			output.writeBytes(3, conversationState_);
		}
		if (microphoneMode_ != com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode.MICROPHONE_MODE_UNSPECIFIED
			.getNumber()) {
			output.writeEnum(4, microphoneMode_);
		}
		if (volumePercentage_ != 0) {
			output.writeInt32(5, volumePercentage_);
		}
	}

	public int getSerializedSize () {
		int size = memoizedSize;
		if (size != -1) return size;

		size = 0;
		if (!getSpokenRequestTextBytes().isEmpty()) {
			size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, spokenRequestText_);
		}
		if (!getSpokenResponseTextBytes().isEmpty()) {
			size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, spokenResponseText_);
		}
		if (!conversationState_.isEmpty()) {
			size += com.google.protobuf.CodedOutputStream.computeBytesSize(3, conversationState_);
		}
		if (microphoneMode_ != com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode.MICROPHONE_MODE_UNSPECIFIED
			.getNumber()) {
			size += com.google.protobuf.CodedOutputStream.computeEnumSize(4, microphoneMode_);
		}
		if (volumePercentage_ != 0) {
			size += com.google.protobuf.CodedOutputStream.computeInt32Size(5, volumePercentage_);
		}
		memoizedSize = size;
		return size;
	}

	private static final long serialVersionUID = 0L;

	@java.lang.Override
	public boolean equals (final java.lang.Object obj) {
		if (obj == this) {
			return true;
		}
		if (!(obj instanceof com.google.assistant.embedded.v1alpha1.ConverseResult)) {
			return super.equals(obj);
		}
		com.google.assistant.embedded.v1alpha1.ConverseResult other = (com.google.assistant.embedded.v1alpha1.ConverseResult)obj;

		boolean result = true;
		result = result && getSpokenRequestText().equals(other.getSpokenRequestText());
		result = result && getSpokenResponseText().equals(other.getSpokenResponseText());
		result = result && getConversationState().equals(other.getConversationState());
		result = result && microphoneMode_ == other.microphoneMode_;
		result = result && (getVolumePercentage() == other.getVolumePercentage());
		return result;
	}

	@java.lang.Override
	public int hashCode () {
		if (memoizedHashCode != 0) {
			return memoizedHashCode;
		}
		int hash = 41;
		hash = (19 * hash) + getDescriptor().hashCode();
		hash = (37 * hash) + SPOKEN_REQUEST_TEXT_FIELD_NUMBER;
		hash = (53 * hash) + getSpokenRequestText().hashCode();
		hash = (37 * hash) + SPOKEN_RESPONSE_TEXT_FIELD_NUMBER;
		hash = (53 * hash) + getSpokenResponseText().hashCode();
		hash = (37 * hash) + CONVERSATION_STATE_FIELD_NUMBER;
		hash = (53 * hash) + getConversationState().hashCode();
		hash = (37 * hash) + MICROPHONE_MODE_FIELD_NUMBER;
		hash = (53 * hash) + microphoneMode_;
		hash = (37 * hash) + VOLUME_PERCENTAGE_FIELD_NUMBER;
		hash = (53 * hash) + getVolumePercentage();
		hash = (29 * hash) + unknownFields.hashCode();
		memoizedHashCode = hash;
		return hash;
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (com.google.protobuf.ByteString data)
		throws com.google.protobuf.InvalidProtocolBufferException {
		return PARSER.parseFrom(data);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (com.google.protobuf.ByteString data,
		com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException {
		return PARSER.parseFrom(data, extensionRegistry);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (byte[] data)
		throws com.google.protobuf.InvalidProtocolBufferException {
		return PARSER.parseFrom(data);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (byte[] data,
		com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException {
		return PARSER.parseFrom(data, extensionRegistry);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (java.io.InputStream input)
		throws java.io.IOException {
		return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (java.io.InputStream input,
		com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException {
		return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseDelimitedFrom (java.io.InputStream input)
		throws java.io.IOException {
		return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseDelimitedFrom (java.io.InputStream input,
		com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException {
		return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input, extensionRegistry);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (com.google.protobuf.CodedInputStream input)
		throws java.io.IOException {
		return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult parseFrom (com.google.protobuf.CodedInputStream input,
		com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException {
		return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input, extensionRegistry);
	}

	public Builder newBuilderForType () {
		return newBuilder();
	}

	public static Builder newBuilder () {
		return DEFAULT_INSTANCE.toBuilder();
	}

	public static Builder newBuilder (com.google.assistant.embedded.v1alpha1.ConverseResult prototype) {
		return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
	}

	public Builder toBuilder () {
		return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
	}

	@java.lang.Override
	protected Builder newBuilderForType (com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
		Builder builder = new Builder(parent);
		return builder;
	}

	/**
	 * <pre>
	 * The semantic result for the user's spoken query.
	 * </pre>
	 *
	 * Protobuf type {@code google.assistant.embedded.v1alpha1.ConverseResult} */
	public static final class Builder extends com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
		// @@protoc_insertion_point(builder_implements:google.assistant.embedded.v1alpha1.ConverseResult)
		com.google.assistant.embedded.v1alpha1.ConverseResultOrBuilder {
		public static final com.google.protobuf.Descriptors.Descriptor getDescriptor () {
			return com.google.assistant.embedded.v1alpha1.AssistantProto.internal_static_google_assistant_embedded_v1alpha1_ConverseResult_descriptor;
		}

		protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable internalGetFieldAccessorTable () {
			return com.google.assistant.embedded.v1alpha1.AssistantProto.internal_static_google_assistant_embedded_v1alpha1_ConverseResult_fieldAccessorTable
				.ensureFieldAccessorsInitialized(com.google.assistant.embedded.v1alpha1.ConverseResult.class,
					com.google.assistant.embedded.v1alpha1.ConverseResult.Builder.class);
		}

		// Construct using com.google.assistant.embedded.v1alpha1.ConverseResult.newBuilder()
		private Builder () {
			maybeForceBuilderInitialization();
		}

		private Builder (com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
			super(parent);
			maybeForceBuilderInitialization();
		}

		private void maybeForceBuilderInitialization () {
			if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
			}
		}

		public Builder clear () {
			super.clear();
			spokenRequestText_ = "";

			spokenResponseText_ = "";

			conversationState_ = com.google.protobuf.ByteString.EMPTY;

			microphoneMode_ = 0;

			volumePercentage_ = 0;

			return this;
		}

		public com.google.protobuf.Descriptors.Descriptor getDescriptorForType () {
			return com.google.assistant.embedded.v1alpha1.AssistantProto.internal_static_google_assistant_embedded_v1alpha1_ConverseResult_descriptor;
		}

		public com.google.assistant.embedded.v1alpha1.ConverseResult getDefaultInstanceForType () {
			return com.google.assistant.embedded.v1alpha1.ConverseResult.getDefaultInstance();
		}

		public com.google.assistant.embedded.v1alpha1.ConverseResult build () {
			com.google.assistant.embedded.v1alpha1.ConverseResult result = buildPartial();
			if (!result.isInitialized()) {
				throw newUninitializedMessageException(result);
			}
			return result;
		}

		public com.google.assistant.embedded.v1alpha1.ConverseResult buildPartial () {
			com.google.assistant.embedded.v1alpha1.ConverseResult result = new com.google.assistant.embedded.v1alpha1.ConverseResult(
				this);
			result.spokenRequestText_ = spokenRequestText_;
			result.spokenResponseText_ = spokenResponseText_;
			result.conversationState_ = conversationState_;
			result.microphoneMode_ = microphoneMode_;
			result.volumePercentage_ = volumePercentage_;
			onBuilt();
			return result;
		}

		public Builder clone () {
			return (Builder)super.clone();
		}

		public Builder setField (com.google.protobuf.Descriptors.FieldDescriptor field, Object value) {
			return (Builder)super.setField(field, value);
		}

		public Builder clearField (com.google.protobuf.Descriptors.FieldDescriptor field) {
			return (Builder)super.clearField(field);
		}

		public Builder clearOneof (com.google.protobuf.Descriptors.OneofDescriptor oneof) {
			return (Builder)super.clearOneof(oneof);
		}

		public Builder setRepeatedField (com.google.protobuf.Descriptors.FieldDescriptor field, int index, Object value) {
			return (Builder)super.setRepeatedField(field, index, value);
		}

		public Builder addRepeatedField (com.google.protobuf.Descriptors.FieldDescriptor field, Object value) {
			return (Builder)super.addRepeatedField(field, value);
		}

		public Builder mergeFrom (com.google.protobuf.Message other) {
			if (other instanceof com.google.assistant.embedded.v1alpha1.ConverseResult) {
				return mergeFrom((com.google.assistant.embedded.v1alpha1.ConverseResult)other);
			} else {
				super.mergeFrom(other);
				return this;
			}
		}

		public Builder mergeFrom (com.google.assistant.embedded.v1alpha1.ConverseResult other) {
			if (other == com.google.assistant.embedded.v1alpha1.ConverseResult.getDefaultInstance()) return this;
			if (!other.getSpokenRequestText().isEmpty()) {
				spokenRequestText_ = other.spokenRequestText_;
				onChanged();
			}
			if (!other.getSpokenResponseText().isEmpty()) {
				spokenResponseText_ = other.spokenResponseText_;
				onChanged();
			}
			if (other.getConversationState() != com.google.protobuf.ByteString.EMPTY) {
				setConversationState(other.getConversationState());
			}
			if (other.microphoneMode_ != 0) {
				setMicrophoneModeValue(other.getMicrophoneModeValue());
			}
			if (other.getVolumePercentage() != 0) {
				setVolumePercentage(other.getVolumePercentage());
			}
			onChanged();
			return this;
		}

		public final boolean isInitialized () {
			return true;
		}

		public Builder mergeFrom (com.google.protobuf.CodedInputStream input,
			com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws java.io.IOException {
			com.google.assistant.embedded.v1alpha1.ConverseResult parsedMessage = null;
			try {
				parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
			} catch (com.google.protobuf.InvalidProtocolBufferException e) {
				parsedMessage = (com.google.assistant.embedded.v1alpha1.ConverseResult)e.getUnfinishedMessage();
				throw e.unwrapIOException();
			} finally {
				if (parsedMessage != null) {
					mergeFrom(parsedMessage);
				}
			}
			return this;
		}

		private java.lang.Object spokenRequestText_ = "";

		/**
		 * <pre>
		 * *Output-only* The recognized transcript of what the user said.
		 * </pre>
		 *
		 * <code>string spoken_request_text = 1;</code> */
		public java.lang.String getSpokenRequestText () {
			java.lang.Object ref = spokenRequestText_;
			if (!(ref instanceof java.lang.String)) {
				com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString)ref;
				java.lang.String s = bs.toStringUtf8();
				spokenRequestText_ = s;
				return s;
			} else {
				return (java.lang.String)ref;
			}
		}

		/**
		 * <pre>
		 * *Output-only* The recognized transcript of what the user said.
		 * </pre>
		 *
		 * <code>string spoken_request_text = 1;</code> */
		public com.google.protobuf.ByteString getSpokenRequestTextBytes () {
			java.lang.Object ref = spokenRequestText_;
			if (ref instanceof String) {
				com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String)ref);
				spokenRequestText_ = b;
				return b;
			} else {
				return (com.google.protobuf.ByteString)ref;
			}
		}

		/**
		 * <pre>
		 * *Output-only* The recognized transcript of what the user said.
		 * </pre>
		 *
		 * <code>string spoken_request_text = 1;</code> */
		public Builder setSpokenRequestText (java.lang.String value) {
			if (value == null) {
				throw new NullPointerException();
			}

			spokenRequestText_ = value;
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* The recognized transcript of what the user said.
		 * </pre>
		 *
		 * <code>string spoken_request_text = 1;</code> */
		public Builder clearSpokenRequestText () {

			spokenRequestText_ = getDefaultInstance().getSpokenRequestText();
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* The recognized transcript of what the user said.
		 * </pre>
		 *
		 * <code>string spoken_request_text = 1;</code> */
		public Builder setSpokenRequestTextBytes (com.google.protobuf.ByteString value) {
			if (value == null) {
				throw new NullPointerException();
			}
			checkByteStringIsUtf8(value);

			spokenRequestText_ = value;
			onChanged();
			return this;
		}

		private java.lang.Object spokenResponseText_ = "";

		/**
		 * <pre>
		 * *Output-only* The text of the assistant's spoken response. This is only
		 * returned for an IFTTT action.
		 * </pre>
		 *
		 * <code>string spoken_response_text = 2;</code> */
		public java.lang.String getSpokenResponseText () {
			java.lang.Object ref = spokenResponseText_;
			if (!(ref instanceof java.lang.String)) {
				com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString)ref;
				java.lang.String s = bs.toStringUtf8();
				spokenResponseText_ = s;
				return s;
			} else {
				return (java.lang.String)ref;
			}
		}

		/**
		 * <pre>
		 * *Output-only* The text of the assistant's spoken response. This is only
		 * returned for an IFTTT action.
		 * </pre>
		 *
		 * <code>string spoken_response_text = 2;</code> */
		public com.google.protobuf.ByteString getSpokenResponseTextBytes () {
			java.lang.Object ref = spokenResponseText_;
			if (ref instanceof String) {
				com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((java.lang.String)ref);
				spokenResponseText_ = b;
				return b;
			} else {
				return (com.google.protobuf.ByteString)ref;
			}
		}

		/**
		 * <pre>
		 * *Output-only* The text of the assistant's spoken response. This is only
		 * returned for an IFTTT action.
		 * </pre>
		 *
		 * <code>string spoken_response_text = 2;</code> */
		public Builder setSpokenResponseText (java.lang.String value) {
			if (value == null) {
				throw new NullPointerException();
			}

			spokenResponseText_ = value;
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* The text of the assistant's spoken response. This is only
		 * returned for an IFTTT action.
		 * </pre>
		 *
		 * <code>string spoken_response_text = 2;</code> */
		public Builder clearSpokenResponseText () {

			spokenResponseText_ = getDefaultInstance().getSpokenResponseText();
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* The text of the assistant's spoken response. This is only
		 * returned for an IFTTT action.
		 * </pre>
		 *
		 * <code>string spoken_response_text = 2;</code> */
		public Builder setSpokenResponseTextBytes (com.google.protobuf.ByteString value) {
			if (value == null) {
				throw new NullPointerException();
			}
			checkByteStringIsUtf8(value);

			spokenResponseText_ = value;
			onChanged();
			return this;
		}

		private com.google.protobuf.ByteString conversationState_ = com.google.protobuf.ByteString.EMPTY;

		/**
		 * <pre>
		 * *Output-only* State information for subsequent `ConverseRequest`. This
		 * value should be saved in the client and returned in the
		 * `conversation_state` with the next `ConverseRequest`. (The client does not
		 * need to interpret or otherwise use this value.) There is no need to save
		 * this information across device restarts.
		 * </pre>
		 *
		 * <code>bytes conversation_state = 3;</code> */
		public com.google.protobuf.ByteString getConversationState () {
			return conversationState_;
		}

		/**
		 * <pre>
		 * *Output-only* State information for subsequent `ConverseRequest`. This
		 * value should be saved in the client and returned in the
		 * `conversation_state` with the next `ConverseRequest`. (The client does not
		 * need to interpret or otherwise use this value.) There is no need to save
		 * this information across device restarts.
		 * </pre>
		 *
		 * <code>bytes conversation_state = 3;</code> */
		public Builder setConversationState (com.google.protobuf.ByteString value) {
			if (value == null) {
				throw new NullPointerException();
			}

			conversationState_ = value;
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* State information for subsequent `ConverseRequest`. This
		 * value should be saved in the client and returned in the
		 * `conversation_state` with the next `ConverseRequest`. (The client does not
		 * need to interpret or otherwise use this value.) There is no need to save
		 * this information across device restarts.
		 * </pre>
		 *
		 * <code>bytes conversation_state = 3;</code> */
		public Builder clearConversationState () {

			conversationState_ = getDefaultInstance().getConversationState();
			onChanged();
			return this;
		}

		private int microphoneMode_ = 0;

		/**
		 * <pre>
		 * *Output-only* Specifies the mode of the microphone after this `Converse`
		 * RPC is processed.
		 * </pre>
		 *
		 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
		public int getMicrophoneModeValue () {
			return microphoneMode_;
		}

		/**
		 * <pre>
		 * *Output-only* Specifies the mode of the microphone after this `Converse`
		 * RPC is processed.
		 * </pre>
		 *
		 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
		public Builder setMicrophoneModeValue (int value) {
			microphoneMode_ = value;
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* Specifies the mode of the microphone after this `Converse`
		 * RPC is processed.
		 * </pre>
		 *
		 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
		public com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode getMicrophoneMode () {
			com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode result = com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode
				.valueOf(microphoneMode_);
			return result == null ? com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode.UNRECOGNIZED : result;
		}

		/**
		 * <pre>
		 * *Output-only* Specifies the mode of the microphone after this `Converse`
		 * RPC is processed.
		 * </pre>
		 *
		 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
		public Builder setMicrophoneMode (com.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode value) {
			if (value == null) {
				throw new NullPointerException();
			}

			microphoneMode_ = value.getNumber();
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* Specifies the mode of the microphone after this `Converse`
		 * RPC is processed.
		 * </pre>
		 *
		 * <code>.google.assistant.embedded.v1alpha1.ConverseResult.MicrophoneMode microphone_mode = 4;</code> */
		public Builder clearMicrophoneMode () {

			microphoneMode_ = 0;
			onChanged();
			return this;
		}

		private int volumePercentage_;

		/**
		 * <pre>
		 * *Output-only* Updated volume level. The value will be 0 or omitted
		 * (indicating no change) unless a voice command such as "Increase the volume"
		 * or "Set volume level 4" was recognized, in which case the value will be
		 * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
		 * Typically, a client should use this volume level when playing the
		 * `audio_out` data, and retain this value as the current volume level and
		 * supply it in the `AudioOutConfig` of the next `ConverseRequest`. (Some
		 * clients may also implement other ways to allow the current volume level to
		 * be changed, for example, by providing a knob that the user can turn.)
		 * </pre>
		 *
		 * <code>int32 volume_percentage = 5;</code> */
		public int getVolumePercentage () {
			return volumePercentage_;
		}

		/**
		 * <pre>
		 * *Output-only* Updated volume level. The value will be 0 or omitted
		 * (indicating no change) unless a voice command such as "Increase the volume"
		 * or "Set volume level 4" was recognized, in which case the value will be
		 * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
		 * Typically, a client should use this volume level when playing the
		 * `audio_out` data, and retain this value as the current volume level and
		 * supply it in the `AudioOutConfig` of the next `ConverseRequest`. (Some
		 * clients may also implement other ways to allow the current volume level to
		 * be changed, for example, by providing a knob that the user can turn.)
		 * </pre>
		 *
		 * <code>int32 volume_percentage = 5;</code> */
		public Builder setVolumePercentage (int value) {

			volumePercentage_ = value;
			onChanged();
			return this;
		}

		/**
		 * <pre>
		 * *Output-only* Updated volume level. The value will be 0 or omitted
		 * (indicating no change) unless a voice command such as "Increase the volume"
		 * or "Set volume level 4" was recognized, in which case the value will be
		 * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
		 * Typically, a client should use this volume level when playing the
		 * `audio_out` data, and retain this value as the current volume level and
		 * supply it in the `AudioOutConfig` of the next `ConverseRequest`. (Some
		 * clients may also implement other ways to allow the current volume level to
		 * be changed, for example, by providing a knob that the user can turn.)
		 * </pre>
		 *
		 * <code>int32 volume_percentage = 5;</code> */
		public Builder clearVolumePercentage () {

			volumePercentage_ = 0;
			onChanged();
			return this;
		}

		public final Builder setUnknownFields (final com.google.protobuf.UnknownFieldSet unknownFields) {
			return this;
		}

		public final Builder mergeUnknownFields (final com.google.protobuf.UnknownFieldSet unknownFields) {
			return this;
		}

		// @@protoc_insertion_point(builder_scope:google.assistant.embedded.v1alpha1.ConverseResult)
	}

	// @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha1.ConverseResult)
	private static final com.google.assistant.embedded.v1alpha1.ConverseResult DEFAULT_INSTANCE;
	static {
		DEFAULT_INSTANCE = new com.google.assistant.embedded.v1alpha1.ConverseResult();
	}

	public static com.google.assistant.embedded.v1alpha1.ConverseResult getDefaultInstance () {
		return DEFAULT_INSTANCE;
	}

	private static final com.google.protobuf.Parser<ConverseResult> PARSER = new com.google.protobuf.AbstractParser<ConverseResult>() {
		public ConverseResult parsePartialFrom (com.google.protobuf.CodedInputStream input,
			com.google.protobuf.ExtensionRegistryLite extensionRegistry) throws com.google.protobuf.InvalidProtocolBufferException {
			return new ConverseResult(input, extensionRegistry);
		}
	};

	public static com.google.protobuf.Parser<ConverseResult> parser () {
		return PARSER;
	}

	@java.lang.Override
	public com.google.protobuf.Parser<ConverseResult> getParserForType () {
		return PARSER;
	}

	public com.google.assistant.embedded.v1alpha1.ConverseResult getDefaultInstanceForType () {
		return DEFAULT_INSTANCE;
	}

}
